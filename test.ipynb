{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, ChatMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from ragas import EvaluationDataset, RunConfig, evaluate\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, LLMContextPrecisionWithReference, AnswerRelevancy\n",
    "\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "\n",
    "from textwrap import dedent\n",
    "from operator import itemgetter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurant_data\n",
      "vector_store/chroma/bluer_db\n",
      "text-embedding-3-small\n",
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "PERSIST_DIRECTORY = os.getenv(\"PERSIST_DIRECTORY\")\n",
    "EMBEDDING_MODEL_NAME = os.getenv(\"EMBEDDING_NAME\")\n",
    "embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "print(COLLECTION_NAME)\n",
    "print(PERSIST_DIRECTORY)\n",
    "print(EMBEDDING_MODEL_NAME)\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: 예약 가능한 한식당으로는 \"한식당 A\"를 추천합니다. 이곳은 전통 한식을 현대적으로 재해석한 메뉴를 제공하며, 예약이 필수입니다. 또한, 분위기가 아늑하고 서비스가 뛰어나 많은 손님들에게 사랑받고 있습니다. 예약을 원하시면 미리 전화나 온라인으로 확인해 보세요.\n",
      "Question: 예약 가능한 한식당 추천해줘.\n",
      "Expected: 예약 가능한 한식당으로는 \"한식당 A\"를 추천합니다. 이곳은 전통적인 한식을 제공하며, 예약이 가능하니 미리 전화나 온라인으로 예약하시는 것이 좋습니다. 추가적인 정보가 필요하시면 말씀해 주세요!\n",
      "Generated: 예약 가능한 한식당으로는 \"한식당 A\"를 추천합니다. 이곳은 전통 한식을 현대적으로 재해석한 메뉴를 제공하며, 예약이 필수입니다. 또한, 분위기가 아늑하고 서비스가 뛰어나 많은 손님들에게 사랑받고 있습니다. 예약을 원하시면 미리 전화나 온라인으로 확인해 보세요.\n",
      "Correct: False\n",
      "BLEU Score: 0.25\n",
      "ROUGE: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      "Precision: 0.42\n",
      "Recall: 0.57\n",
      "F1 Score: 0.48\n",
      "------------------------------\n",
      "Question: 리본개수가 2개인 식당을 추천해주세요.\n",
      "Expected: 리본개수가 2개인 식당으로는 \"이탈리안 레스토랑\"이 있습니다. 이곳은 다양한 파스타와 피자를 제공하며, 아늑한 분위기에서 식사를 즐길 수 있습니다.\n",
      "Generated: 리본개수가 2개인 식당으로는 \"이탈리안 레스토랑\"이 있습니다. 이곳은 다양한 파스타와 피자를 제공하며, 아늑한 분위기에서 식사를 즐길 수 있습니다. 추천 메뉴로는 트러플 크림 파스타와 마르게리타 피자가 있습니다.\n",
      "Correct: True\n",
      "BLEU Score: 0.66\n",
      "ROUGE: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      "Precision: 0.64\n",
      "Recall: 0.94\n",
      "F1 Score: 0.76\n",
      "------------------------------\n",
      "Question: 프랑스식을 추천해주세요.\n",
      "Expected: 프랑스식 요리를 즐기고 싶으시다면, \"프렌치 레스토랑\"을 추천드립니다. 이곳에서는 전통적인 프랑스 요리와 함께 다양한 와인을 즐길 수 있습니다. 분위기도 아늑하고 고급스러운 편이라 특별한 날에 방문하기 좋습니다. 메뉴에는 에스카르고, 부야베스, 크렘 브륄레 등 다양한 프랑스 요리가 포함되어 있습니다.\n",
      "Generated: 프랑스식 요리를 즐기고 싶으시다면, \"프렌치 레스토랑\"을 추천드립니다. 이곳에서는 전통적인 프랑스 요리와 함께 다양한 와인을 즐길 수 있습니다. 분위기도 아늑하고 고급스러운 편이라 특별한 날에 방문하기 좋습니다. 메뉴에는 에스카르고, 부야베스, 크렘 브륄레 등 다양한 프랑스 요리가 준비되어 있습니다.\n",
      "Correct: False\n",
      "BLEU Score: 0.95\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n",
      "Precision: 0.89\n",
      "Recall: 0.89\n",
      "F1 Score: 0.89\n",
      "------------------------------\n",
      "Question: 홍보각 식당의 정보를 알려주세요\n",
      "Expected: 홍보각 식당은 한국 전통 음식을 전문으로 하는 곳입니다. 이 식당은 다양한 한식 메뉴를 제공하며, 특히 비빔밥과 불고기가 인기입니다. 아늑한 분위기와 친절한 서비스로 많은 손님들에게 사랑받고 있습니다. 식당의 위치는 서울 중심가에 있으며, 대중교통으로 쉽게 접근할 수 있습니다. 추가적인 정보가 필요하시면 말씀해 주세요!\n",
      "Generated: 홍보각 식당은 한국 전통 음식을 전문으로 하는 곳입니다. 이 식당은 특히 비빔밥과 불고기로 유명하며, 신선한 재료를 사용하여 맛을 극대화합니다. 또한, 아늑한 분위기와 친절한 서비스로 많은 손님들에게 사랑받고 있습니다. \n",
      "\n",
      "리본개수는 4개로, 평점이 높아 많은 사람들이 추천하는 식당입니다. 다양한 메뉴와 함께 전통적인 한국의 맛을 경험해보실 수 있습니다.\n",
      "Correct: False\n",
      "BLEU Score: 0.37\n",
      "ROUGE: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n",
      "Precision: 0.47\n",
      "Recall: 0.51\n",
      "F1 Score: 0.49\n",
      "------------------------------\n",
      "Results saved to evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# vector_db에서 데이터 불러오기\n",
    "########################################################\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "\n",
    "\n",
    "# GPT Model 생성\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0 \n",
    ")\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 50,\n",
    "        \"fetch_k\": 200,\n",
    "        \"lambda_mult\": 0.5,\n",
    "        # \"filters\": {\"리본개수\": {\"$gte\": 0}}\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        당신은 한국의 식당을 소개하는 인공지능 비서입니다. \n",
    "        반드시 질문에 대해서 [context]에 주어진 내용을 바탕으로 답변을 해주세요. \n",
    "        질문에 '리본개수', '평점', '몇 개'라는 키워드가 포함된 경우, [context]에서 \"리본개수\" 항목을 확인해 답변하세요.\n",
    "        리본개수는 평점과 같은 의미를 가집니다.\n",
    "        [context]\n",
    "        {context}\n",
    "    \"\"\")),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Chain 생성\n",
    "#########################################\n",
    "\n",
    "def content_from_doc(docs:list[Document]):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "chain =  {'context': retriever  | RunnableLambda(content_from_doc), 'question': RunnablePassthrough()}  | prompt_template | model | StrOutputParser()\n",
    "\n",
    "# QUERY 실행 및 응답 확인\n",
    "QUERY = \"예약 가능한 한식당 추천해줘.\"\n",
    "response = chain.invoke(QUERY)\n",
    "print(\"Generated Response:\", response)\n",
    "\n",
    "# 테스트 데이터 초기화\n",
    "initial_test_data = [\n",
    "    {\"question\": \"예약 가능한 한식당 추천해줘.\", \"expected_answer\": \"\"},\n",
    "    {\"question\": \"리본개수가 2개인 식당을 추천해주세요.\", \"expected_answer\": \"\"},\n",
    "    {\"question\": \"프랑스식을 추천해주세요.\", \"expected_answer\": \"\"},\n",
    "    {\"question\": \"홍보각 식당의 정보를 알려주세요\", \"expected_answer\": \"\"}\n",
    "]\n",
    "\n",
    "# expected_answer 생성\n",
    "def generate_expected_answers(chain, test_data):\n",
    "    for test_case in test_data:\n",
    "        question = test_case[\"question\"]\n",
    "        response = chain.invoke(question)\n",
    "        test_case[\"expected_answer\"] = response.strip()\n",
    "    return test_data\n",
    "\n",
    "test_data = generate_expected_answers(chain, initial_test_data)\n",
    "\n",
    "# 성능 평가 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_chain(chain, test_data):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    results = []\n",
    "\n",
    "    for test_case in test_data:\n",
    "        question = test_case[\"question\"]\n",
    "        expected_answer = test_case[\"expected_answer\"]\n",
    "\n",
    "        response = chain.invoke(question)\n",
    "        generated_answer = response.strip()\n",
    "\n",
    "        correct = expected_answer in generated_answer\n",
    "        bleu_score = sentence_bleu([expected_answer.split()], generated_answer.split())\n",
    "        rouge_scores = scorer.score(generated_answer, expected_answer)\n",
    "        precision = len(set(generated_answer.split()) & set(expected_answer.split())) / len(generated_answer.split())\n",
    "        recall = len(set(generated_answer.split()) & set(expected_answer.split())) / len(expected_answer.split())\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"correct\": correct,\n",
    "            \"bleu_score\": bleu_score,\n",
    "            \"rouge\": rouge_scores,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# 평가 실행\n",
    "results = evaluate_chain(chain, test_data)\n",
    "\n",
    "# 결과 출력\n",
    "for result in results:\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Expected: {result['expected_answer']}\")\n",
    "    print(f\"Generated: {result['generated_answer']}\")\n",
    "    print(f\"Correct: {result['correct']}\")\n",
    "    print(f\"BLEU Score: {result['bleu_score']:.2f}\")\n",
    "    # ROUGE-1은 단어 단위의 겹치는 개수를 측정합니다.\n",
    "    # Precision: 생성된 텍스트의 단어 중 정답 텍스트에 포함된 단어의 비율.\n",
    "    # Recall: 정답 텍스트의 단어 중 생성된 텍스트에 포함된 단어의 비율.\n",
    "    # F-measure: Precision과 Recall의 조화 평균.\n",
    "    print(f\"ROUGE: {result['rouge']}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1_score']:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 결과 저장\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"evaluation_results.csv\", index=False)\n",
    "print(\"Results saved to evaluation_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
